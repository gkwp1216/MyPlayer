"""
MP ê²Œì„ ì „ìš© ì‹¤ì‹œê°„ ê°•í™”í•™ìŠµ í™˜ê²½
ë©”ì´í”ŒìŠ¤í† ë¦¬ ì‚¬ëƒ¥ ì „ìš© í–‰ë™ ë° ë³´ìƒ ì²´ê³„
"""
from gymnasium import spaces
import numpy as np
import cv2
import time
import keyboard
from pathlib import Path

from src.rl_env_base import BaseRealtimeEnv


class MPRealtimeEnv(BaseRealtimeEnv):
    """MP ê²Œì„ ì‹¤ì‹œê°„ í™˜ê²½"""
    
    def __init__(self, frame_width=84, frame_height=84, frame_stack=4, frame_skip=4):
        super().__init__(
            game="MP",
            frame_width=frame_width,
            frame_height=frame_height,
            frame_stack=frame_stack,
            frame_skip=frame_skip
        )
        
        # MP ì „ìš© í–‰ë™ ê³µê°„ (ê¸°ë³¸ 8ê°œë¡œ ì‹œì‘)
        # 0: idle, 1: left, 2: right, 3: up, 4: down
        # 5: attack, 6: skill_1, 7: jump
        self.action_space = spaces.Discrete(8)
        
        # ê´€ì¸¡ ê³µê°„: ê·¸ë ˆì´ìŠ¤ì¼€ì¼ í”„ë ˆì„ ìŠ¤íƒ
        self.observation_space = spaces.Box(
            low=0, high=255,
            shape=(frame_stack, frame_height, frame_width),
            dtype=np.uint8
        )
        
        # MP ì „ìš© ìƒíƒœ
        self.last_move_direction = 'right'
        self.stuck_count = 0
        self.last_exp_pixels = None
        
        print("âœ… MP í™˜ê²½ ì´ˆê¸°í™” ì™„ë£Œ")
        print("ğŸ“‹ í–‰ë™ ê³µê°„: 0=idle, 1=left, 2=right, 3=up, 4=down, 5=attack, 6=skill, 7=jump")
    
    def reset(self, seed=None, options=None):
        """MP í™˜ê²½ ì´ˆê¸°í™”"""
        obs, info = super().reset(seed, options)
        
        # MP ì „ìš© ìƒíƒœ ë¦¬ì…‹
        self.last_move_direction = 'right'
        self.stuck_count = 0
        self.last_exp_pixels = None
        
        return obs, info
    
    def step(self, action):
        """í–‰ë™ ì‹¤í–‰ ë° ë³´ìƒ ê³„ì‚°"""
        total_reward = 0.0
        done = False
        
        for _ in range(self.frame_skip):
            self._execute_action(action)
            time.sleep(0.01)
            
            current_frame = self._capture_frame()
            
            # ë³´ìƒ ëˆ„ì 
            step_reward = self._calculate_reward(action, current_frame)
            total_reward += step_reward
            
            # í”„ë ˆì„ ë²„í¼ ì—…ë°ì´íŠ¸
            processed = self._preprocess_frame(current_frame)
            self.frame_buffer.append(processed)
            self.last_frame = current_frame.copy()
            
            # ì¢…ë£Œ ì¡°ê±´
            self.step_count += 1
            if self.step_count >= 1000:
                done = True
                break
        
        self.episode_reward += total_reward
        observation = self._get_observation()
        info = {'step': self.step_count, 'episode_reward': self.episode_reward}
        
        return observation, total_reward, done, False, info
    
    def _execute_action(self, action):
        """MP ì „ìš© í–‰ë™ ì‹¤í–‰"""
        action_map = {
            0: None,  # idle
            1: self.keybindings.get('move_left', 'left'),
            2: self.keybindings.get('move_right', 'right'),
            3: self.keybindings.get('move_up', 'up'),
            4: self.keybindings.get('move_down', 'down'),
            5: self.keybindings.get('attack', 'ctrl'),  # MP ê¸°ë³¸ ê³µê²©
            6: self.keybindings.get('skill_key', 'a'),   # ì£¼ë ¥ ìŠ¤í‚¬
            7: self.keybindings.get('jump', 'alt')       # ì í”„
        }
        
        key = action_map.get(action)
        if key:
            if action == 5:  # ê³µê²©
                keyboard.press(key)
                time.sleep(0.2)
                keyboard.release(key)
            elif action == 6:  # ìŠ¤í‚¬
                keyboard.press(key)
                time.sleep(0.15)
                keyboard.release(key)
            elif action == 7:  # ì í”„
                keyboard.press(key)
                time.sleep(0.1)
                keyboard.release(key)
            elif action in [1, 2, 3, 4]:  # ì´ë™
                keyboard.press(key)
                time.sleep(0.05)
                keyboard.release(key)
                
                # ì¢Œìš° ë°©í–¥ ê¸°ì–µ
                if action == 1:
                    self.last_move_direction = 'left'
                elif action == 2:
                    self.last_move_direction = 'right'
    
    def _calculate_reward(self, action, current_frame):
        """MP ì „ìš© ë³´ìƒ ê³„ì‚°"""
        reward = 0.0
        
        # 1. ê²½í—˜ì¹˜ íšë“ (ìµœìš°ì„ !)
        exp_reward = self._detect_exp_gain(current_frame)
        if exp_reward > 0:
            reward += exp_reward
            print(f"ğŸ‰ ëª¬ìŠ¤í„° ì²˜ì¹˜! +{exp_reward}")
        
        # 2. í™”ë©´ ë³€í™” ê°ì§€
        change_score = 0.0
        if self.last_frame is not None:
            diff = cv2.absdiff(current_frame, self.last_frame)
            change_score = np.mean(diff) / 255.0
            
            # ë²½ ì¶©ëŒ ê°ì§€
            if action in [1, 2] and change_score < 0.03:
                self.stuck_count += 1
                reward -= 0.5
                if self.stuck_count > 3:
                    reward -= 0.8
            else:
                self.stuck_count = max(0, self.stuck_count - 1)
            
            # ê³µê²©/ìŠ¤í‚¬ ì¤‘ íƒ€ê²© ì´í™íŠ¸
            if action in [5, 6] and change_score > 0.1:
                reward += 0.3
            
            # ì •ì  í™”ë©´ í˜ë„í‹°
            if change_score < 0.05 and action not in [5, 6]:
                reward -= 0.08
        
        # 3. í–‰ë™ ì‹œí€€ìŠ¤ ë³´ìƒ
        if len(self.action_history) >= 2:
            prev_action = self.action_history[-1]
            
            # ì´ë™â†’ê³µê²©/ìŠ¤í‚¬ (ì¢‹ì€ íŒ¨í„´)
            if prev_action in [1, 2] and action in [5, 6]:
                reward += 0.4
            
            # ê³µê²©â†’ì´ë™ (ë‹¤ìŒ ëª¬ìŠ¤í„°)
            elif prev_action in [5, 6] and action in [1, 2]:
                reward += 0.2
            
            # ë‹¨ì¡°ë¡œì›€ í˜ë„í‹°
            recent_actions = list(self.action_history)[-5:]
            if len(set(recent_actions)) == 1 and action == recent_actions[0]:
                reward -= 0.12
        
        # 4. í–‰ë™ë³„ ê¸°ë³¸ ë³´ìƒ
        if action in [5, 6]:  # ê³µê²©/ìŠ¤í‚¬
            reward += 0.5
        elif action in [1, 2]:  # ì¢Œìš° ì´ë™
            reward += 0.1
        elif action == 7:  # ì í”„
            reward += 0.05
        elif action == 0:  # idle
            reward -= 0.25
        
        # í–‰ë™ ì´ë ¥ ì—…ë°ì´íŠ¸
        self.action_history.append(action)
        self.last_action = action
        self.last_action_time = time.time()
        
        return reward
    
    def _detect_exp_gain(self, frame):
        """ê²½í—˜ì¹˜ íšë“ ê°ì§€ (ë…¸ë€ìƒ‰ ë°” ì¦ê°€)"""
        if not self.roi_settings or 'exp_bar' not in self.roi_settings:
            return 0.0
        
        roi = self.roi_settings['exp_bar']
        x, y, w, h = roi['x'], roi['y'], roi['w'], roi['h']
        
        exp_roi = frame[y:y+h, x:x+w]
        hsv_roi = cv2.cvtColor(exp_roi, cv2.COLOR_BGR2HSV)
        lower_yellow = np.array([20, 100, 100])
        upper_yellow = np.array([30, 255, 255])
        mask = cv2.inRange(hsv_roi, lower_yellow, upper_yellow)
        yellow_pixels = np.sum(mask > 0)
        
        reward = 0.0
        if self.last_exp_pixels is not None:
            pixel_diff = yellow_pixels - self.last_exp_pixels
            if pixel_diff > 10:
                reward = 2.0
            elif pixel_diff > 5:
                reward = 0.5
        
        self.last_exp_pixels = yellow_pixels
        return reward


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    env = MPRealtimeEnv()
    obs, info = env.reset()
    
    print("ğŸ® MP í™˜ê²½ í…ŒìŠ¤íŠ¸")
    print(f"ê´€ì¸¡ ê³µê°„: {obs.shape}")
    print(f"í–‰ë™ ê³µê°„: {env.action_space.n}")
    
    for i in range(5):
        action = env.action_space.sample()
        obs, reward, done, truncated, info = env.step(action)
        print(f"Step {i+1}: action={action}, reward={reward:.3f}")
        
        if done:
            break
    
    env.close()
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
